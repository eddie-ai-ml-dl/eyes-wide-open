# Project Summary and Setup Instructions: YOLOv12 Person Cropping with Metadata

## Project Objective

The overarching goal of this project is to implement a robust, two-stage image recognition pipeline:
1.  **Stage 1 (Current Focus):** Utilize the Ultralytics YOLOv12 model to detect 'person' objects within images, intelligently crop these detections, and prepare them for a downstream classification task.
2.  **Stage 2 (Future):** Develop and train a custom image classification model to distinguish between 'person with hat' and 'person without hat' using the prepared cropped images.

This document focuses specifically on setting up and executing **Stage 1: Intelligent Cropping and Data Preparation**.

## Accomplishments So Far

We have successfully designed and implemented a Python project structure and a core script (`test_yolov12_img_cropping.py`) that performs the following:

1.  **YOLOv12 Integration:** Loaded the pre-trained `yolo12n.pt` model from Ultralytics to perform object detection.
2.  **Targeted Detection & Cropping:** Specifically identified and extracted bounding boxes for 'person' class objects.
3.  **Enhanced Cropping Best Practices:**
    *   Applied a configurable **padding ratio** around detected bounding boxes to ensure full object capture (e.g., a hat's brim).
    *   Implemented a **minimum dimension filter** to discard very small or low-quality person detections.
    *   Transformed varying aspect-ratio crops into **standardized square images** by padding (with black bars) to preserve aspect ratio.
    *   **Resized** all final crops to a uniform target resolution (e.g., 224x224 pixels), which is ideal for downstream image classifiers.
4.  **Comprehensive Metadata Tracking:**
    *   Generated a `cropped_persons_metadata.json` file alongside the cropped images.
    *   This JSON tracks critical information for each crop, including:
        *   Unique crop ID.
        *   Original image source.
        *   YOLO model used and confidence score.
        *   Original and padded bounding box coordinates.
        *   Dimensions at various stages.
        *   Configuration parameters used during cropping (padding ratio, min size filter, target resolution).
        *   Timestamps and data lineage placeholders (`status`, `assigned_label`, `label_source`, `dataset_split`) for future pipeline steps.
5.  **Modular Code Architecture:**
    *   Refactored reusable logic into a dedicated `src/utils/` package.
    *   `src/utils/image_processing.py`: Contains generic image transformation functions (like `pad_to_square_and_resize`).
    *   `src/utils/metadata_manager.py`: Handles loading and saving of the project's JSON metadata files.
    *   This significantly improves code readability, maintainability, and reusability.
6.  **Validated Functionality:** Confirmed that the script accurately detects, crops, processes, and stores person images, along with their metadata, using sample images.

---

## Project Instructions: How to Recreate and Run

Follow these steps to set up and run the current project state.

### 1. Prerequisites

Before you begin, ensure you have:

*   **Python 3.8+** installed.
*   **pip** (Python package installer).
*   **Git** (optional, but recommended for version control).

### 2. Project Setup

Create the project directory structure and essential files:

```bash
# Create the root project directory
mkdir eyes-wide-open
cd eyes-wide-open

# Create data directories
mkdir -p data/images data/videos data/cropped_persons

# Create source code directories and __init__.py files
mkdir -p src/utils src/classifier
touch src/__init__.py src/utils/__init__.py src/classifier/__init__.py

# Create scripts directory
mkdir scripts

# Create a placeholder for Ultralytics output
mkdir runs

# Create other essential files
touch requirements.txt .gitignore README.md
```

### 3. Populate Essential Files

Add the following content to the specified files:

#### `requirements.txt`

```
ultralytics
Pillow
```

#### `.gitignore`

```
# Python
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
.venv
env/
venv/
*.egg-info/
.pytest_cache/

# Ultralytics runs
runs/

# Dataset generated output (optional, uncomment if you don't want to track data)
# data/cropped_persons/*.jpg
# data/cropped_persons/cropped_persons_metadata.json

# Jupyter Notebooks
.ipynb_checkpoints/
```

#### `src/utils/image_processing.py`

```python
# eyes-wide-open/src/utils/image_processing.py

from PIL import Image

def pad_to_square_and_resize(image: Image.Image, target_size: int, fill_color=(0, 0, 0)) -> Image.Image:
    """
    Pads an image to a square aspect ratio and then resizes it to a target square dimension.
    Preserves aspect ratio by adding padding bars.

    Args:
        image (PIL.Image.Image): The input image to process.
        target_size (int): The desired square dimension (e.g., 224 for 224x224).
        fill_color (tuple): RGB tuple for the color of the padding bars (default: black).

    Returns:
        PIL.Image.Image: The processed image, square and resized to target_size.
    """
    width, height = image.size
    max_dim = max(width, height)

    # Create a new blank square image
    square_padded_img = Image.new(image.mode, (max_dim, max_dim), fill_color)
    
    # Calculate paste position to center the original crop
    paste_x = (max_dim - width) // 2
    paste_y = (max_dim - height) // 2
    square_padded_img.paste(image, (paste_x, paste_y))

    # Resize to target classifier size using a high-quality filter
    final_resized_image = square_padded_img.resize((target_size, target_size), Image.LANCZOS)
    return final_resized_image
```

#### `src/utils/metadata_manager.py`

```python
# eyes-wide-open/src/utils/metadata_manager.py

import json
import os
import datetime

def load_metadata(filepath: str) -> list:
    """
    Loads metadata from a JSON file. Returns an empty list if file doesn't exist.

    Args:
        filepath (str): The path to the JSON metadata file.

    Returns:
        list: A list of dictionaries representing the metadata.
    """
    if not os.path.exists(filepath):
        return []
    try:
        with open(filepath, 'r') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON from '{filepath}': {e}. Returning empty list.")
        return []
    except Exception as e:
        print(f"Error loading metadata from '{filepath}': {e}. Returning empty list.")
        return []

def save_metadata(data: list, filepath: str):
    """
    Saves metadata (a list of dictionaries) to a JSON file.

    Args:
        data (list): The list of dictionaries to save.
        filepath (str): The path to the output JSON metadata file.
    """
    try:
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=4)
    except Exception as e:
        print(f"Error saving metadata to '{filepath}': {e}")

def update_metadata_entry(metadata: list, crop_id: str, updates: dict) -> list:
    """
    Updates a specific entry in the metadata list identified by crop_id.
    Adds a 'last_updated_timestamp' to the entry.
    Returns the updated metadata list (or original if crop_id not found).

    Args:
        metadata (list): The list of dictionaries (metadata).
        crop_id (str): The unique identifier for the crop to update.
        updates (dict): A dictionary of fields and new values to update.

    Returns:
        list: The metadata list with the specified entry updated.
    """
    found = False
    for entry in metadata:
        if entry.get("crop_id") == crop_id:
            entry.update(updates)
            entry['last_updated_timestamp'] = datetime.datetime.now(datetime.timezone.utc).isoformat(timespec='seconds')
            found = True
            break
    if not found:
        print(f"Warning: Crop ID '{crop_id}' not found in metadata for update.")
    return metadata
```

#### `scripts/test_yolov12_img_cropping.py`

```python
# eyes-wide-open/scripts/test_yolov12_img_cropping.py

from ultralytics import YOLO
import os
from PIL import Image # Still needed here to open the original image
import datetime       # Still needed here to generate the timestamp for a new entry

# --- Import utility functions ---
from src.utils.image_processing import pad_to_square_and_resize
from src.utils.metadata_manager import save_metadata

# --- Configuration ---
# Path to the directory containing your input test images
IMAGE_DIR = os.path.join('..', 'data', 'images')
# Path to the directory where cropped 'person' images will be saved
CROPPED_OUTPUT_DIR = os.path.join('..', 'data', 'cropped_persons')
# Path to the directory where Ultralytics will save annotated (boxes drawn on) images
INFERENCE_OUTPUT_DIR = os.path.join('..', 'runs', 'detect')

# Name of the pre-trained YOLOv12 model to use
MODEL_NAME = 'yolov12n.pt'

# Minimum confidence score for a detection to be considered valid and processed
# Detections below this threshold will be ignored.
CONFIDENCE_THRESHOLD = 0.5

# New Parameters for Cropping Best Practices
CROP_PADDING_RATIO = 0.10
TARGET_CLASSIFIER_SIZE = 224
MIN_CROP_DIMENSION_PX = 50

# Metadata Configuration
METADATA_FILENAME = 'cropped_persons_metadata.json'


def extract_and_store_persons_for_classification():
    """
    Loads a YOLOv12 model, runs inference on images in IMAGE_DIR,
    detects 'person' objects, applies padding, filters by size,
    pads to a square aspect ratio, resizes to a target dimension,
    and saves these processed cropped images to CROPPED_OUTPUT_DIR.
    It also generates a metadata JSON file tracking the process and results.
    """
    print("--- Starting Enhanced Person Extraction Process ---")
    print(f"Model: {MODEL_NAME}, Confidence Threshold: {CONFIDENCE_THRESHOLD}")
    print(f"Crop Padding Ratio: {CROP_PADDING_RATIO}, Target Classifier Size: {TARGET_CLASSIFIER_SIZE}x{TARGET_CLASSIFIER_SIZE}px")
    print(f"Minimum Crop Dimension: {MIN_CROP_DIMENSION_PX}px")

    # --- Ensure output directories exist ---
    try:
        os.makedirs(CROPPED_OUTPUT_DIR, exist_ok=True)
        os.makedirs(INFERENCE_OUTPUT_DIR, exist_ok=True)
        print(f"Ensured '{CROPPED_OUTPUT_DIR}' and '{INFERENCE_OUTPUT_DIR}' exist.")
    except OSError as e:
        print(f"Error creating output directories: {e}. Exiting.")
        return

    # --- Load YOLOv12 Model ---
    print(f"Attempting to load YOLOv12 model: {MODEL_NAME}")
    try:
        model = YOLO(MODEL_NAME)
        print("Model loaded successfully.")
    except Exception as e:
        print(f"Error loading model '{MODEL_NAME}': {e}")
        print("Please ensure you have an active internet connection for first-time download,")
        print("or that the model file exists if loading locally. Exiting.")
        return

    # --- Gather Image Files ---
    image_files = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR)
                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]

    if not image_files:
        print(f"No image files found in '{IMAGE_DIR}'. Please add some images.")
        return

    print(f"Found {len(image_files)} images to process in '{IMAGE_DIR}'.")
    
    total_persons_extracted = 0
    all_crops_metadata = [] # List to store metadata for all generated crops

    try:
        # --- Run Inference ---
        results = model.predict(source=image_files,
                                save=True,
                                project=INFERENCE_OUTPUT_DIR,
                                name='yolov12_person_extraction_for_classifier',
                                conf=CONFIDENCE_THRESHOLD,
                                verbose=False)

        # --- Process Each Image's Results ---
        for i, result in enumerate(results):
            image_path = image_files[i]
            image_filename = os.path.basename(image_path)
            print(f"\n--- Processing detections for: {image_filename} ---")
            
            try:
                original_image = Image.open(image_path).convert("RGB")
            except Exception as img_e:
                print(f"  Error loading original image '{image_filename}': {img_e}. Skipping image.")
                continue
            
            person_count_in_image = 0

            if result.boxes:
                for j, box in enumerate(result.boxes):
                    class_id = int(box.cls[0])
                    label = model.names[class_id]
                    confidence = float(box.conf[0])
                    x1_orig, y1_orig, x2_orig, y2_orig = box.xyxy[0].tolist() 

                    print(f"  - Detected: {label} (Confidence: {confidence:.2f}) [BBox: [{x1_orig:.2f}, {y1_orig:.2f}, {x2_orig:.2f}, {y2_orig:.2f}]]")

                    # --- Extract and Save 'person' Crops ---
                    if label == 'person':
                        # 1. Apply Padding to Bounding Box
                        bbox_width = x2_orig - x1_orig
                        bbox_height = y2_orig - y1_orig
                        
                        pad_x = bbox_width * CROP_PADDING_RATIO / 2
                        pad_y = bbox_height * CROP_PADDING_RATIO / 2

                        x1_padded = max(0, int(x1_orig - pad_x))
                        y1_padded = max(0, int(y1_orig - pad_y))
                        x2_padded = min(original_image.width, int(x2_orig + pad_x))
                        y2_padded = min(original_image.height, int(y2_orig + pad_y))
                        
                        # 2. Filter by Minimum Size
                        current_crop_width = x2_padded - x1_padded
                        current_crop_height = y2_padded - y1_padded

                        if current_crop_width < MIN_CROP_DIMENSION_PX or current_crop_height < MIN_CROP_DIMENSION_PX:
                            print(f"    Skipping small person detection (dim: {current_crop_width}x{current_crop_height}px), below min {MIN_CROP_DIMENSION_PX}px.")
                            continue

                        # 3. Perform Initial Crop with Padding
                        try:
                            padded_crop = original_image.crop((x1_padded, y1_padded, x2_padded, y2_padded))
                        except Exception as crop_e:
                            print(f"    Error during initial crop for person {j}: {crop_e}. Skipping.")
                            continue

                        # 4. Pad to Square Aspect Ratio and Resize (using utility function)
                        final_cropped_image = pad_to_square_and_resize(padded_crop, TARGET_CLASSIFIER_SIZE)
                        
                        # 5. Save the Final Cropped Image
                        base_name = os.path.splitext(image_filename)[0]
                        cropped_filename = f"{base_name}_person_{j}_conf{confidence:.2f}_{TARGET_CLASSIFIER_SIZE}px.jpg"
                        cropped_filepath = os.path.join(CROPPED_OUTPUT_DIR, cropped_filename)
                        
                        try:
                            final_cropped_image.save(cropped_filepath)
                            print(f"    -> Saved processed person crop to: {cropped_filepath}")
                            person_count_in_image += 1
                            total_persons_extracted += 1

                            # 6. Store Metadata for this crop
                            crop_id = f"{base_name}_person_{j}_conf{confidence:.4f}".replace('.', '_')
                            
                            metadata_entry = {
                                "crop_id": crop_id,
                                "original_image_filename": image_filename,
                                "original_image_path": os.path.abspath(image_path),
                                "yolo_model_used": MODEL_NAME,
                                "yolo_confidence_score": confidence,
                                "original_bbox_xyxy": [round(val, 2) for val in [x1_orig, y1_orig, x2_orig, y2_orig]],
                                "padded_bbox_xyxy": [x1_padded, y1_padded, x2_padded, y2_padded],
                                "original_crop_dimensions_wh": [padded_crop.width, padded_crop.height],
                                "final_crop_filename": cropped_filename,
                                "final_crop_path": os.path.abspath(cropped_filepath),
                                "final_crop_resolution_wh": [TARGET_CLASSIFIER_SIZE, TARGET_CLASSIFIER_SIZE],
                                "cropping_timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat(timespec='seconds'),
                                "min_crop_dimension_filter_applied": MIN_CROP_DIMENSION_PX,
                                "crop_padding_ratio_applied": CROP_PADDING_RATIO,
                                "status": "raw_crop_generated",
                                "assigned_label": None,
                                "label_source": None,
                                "labeling_timestamp": None,
                                "dataset_split": None
                            }
                            all_crops_metadata.append(metadata_entry)

                        except Exception as save_e:
                            print(f"    Error saving processed image '{cropped_filename}': {save_e}")
            else:
                print("  No objects detected in this image.")

            if person_count_in_image == 0:
                print(f"  No 'person' objects (above confidence {CONFIDENCE_THRESHOLD} and min size {MIN_CROP_DIMENSION_PX}px) detected in {image_filename}.")

    except Exception as e:
        print(f"\nAn unexpected error occurred during inference or extraction: {e}")
        if "No module named 'PIL'" in str(e):
            print("Hint: The 'Pillow' library is required for image manipulation. Install it with: pip install Pillow")
        print("Hint: Check your image files for corruption or unsupported formats if encountering image-related errors.")

    print(f"\n--- Enhanced Extraction Process Complete ---")
    print(f"Total 'person' images extracted: {total_persons_extracted}")
    print(f"Processed cropped images can be found in: '{CROPPED_OUTPUT_DIR}'")
    print(f"Annotated input images saved in: '{os.path.join(INFERENCE_OUTPUT_DIR, 'yolov12_person_extraction_for_classifier')}'")

    # --- Save Metadata to JSON File (using utility function) ---
    metadata_filepath = os.path.join(CROPPED_OUTPUT_DIR, METADATA_FILENAME)
    try:
        save_metadata(all_crops_metadata, metadata_filepath)
        print(f"Detailed metadata for all crops saved to: '{metadata_filepath}'")
    except Exception as json_e:
        print(f"Error saving metadata to JSON file '{metadata_filepath}': {json_e}")


if __name__ == "__main__":
    extract_and_store_persons_for_classification()
```

### 4. Install Dependencies

From the root of your `eyes-wide-open` directory, run:

```bash
pip install -r requirements.txt
```

### 5. Add Sample Images

Place your test images (e.g., `image_from_water.jpg`) into the `eyes-wide-open/data/images/` directory.

### 6. Run the Cropping Script

Navigate to the `scripts` directory and execute the main script:

```bash
cd eyes-wide-open/scripts
python test_yolov12_img_cropping.py
```

### 7. Verify the Output

After the script completes:

*   **Console Output:** Review the messages in your terminal for detection details, successful saves, and any warnings or errors.
*   **Cropped Images:** Check `eyes-wide-open/data/cropped_persons/`. You should find `.jpg` files for each detected and processed 'person'. They will be square, padded, and resized.
*   **Metadata JSON:** Inside `eyes-wide-open/data/cropped_persons/`, you'll find `cropped_persons_metadata.json`, containing a detailed record of each generated crop.
*   **Annotated Images:** In `eyes-wide-open/runs/detect/yolov12_person_extraction_for_classifier/`, you will find copies of your original images with YOLO's detections drawn on them.
